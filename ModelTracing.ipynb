{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelTracing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-4P5mWrV2US",
        "outputId": "348f090a-efad-4108-828d-afb49a8389b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS4900_Project'...\n",
            "remote: Enumerating objects: 1351, done.\u001b[K\n",
            "remote: Counting objects: 100% (1351/1351), done.\u001b[K\n",
            "remote: Compressing objects: 100% (652/652), done.\u001b[K\n",
            "remote: Total 1351 (delta 477), reused 1122 (delta 374), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1351/1351), 135.11 MiB | 11.78 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ndatkinson/CS4900_Project\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.functional import Tensor\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "%cd /content/CS4900_Project/\n",
        "image = Image.open('2007_000027.jpg')\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "tensor = transform(image)\n",
        "#print(tensor)\n",
        "model = torch.load('unit_tgs_VOC2012.pt')\n",
        "model.eval()\n",
        "\n",
        "tensor = tensor.unsqueeze(0)\n",
        "\n",
        "traced_script_module = torch.jit.trace(model, tensor)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5uJ_F3RUmBoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_traced_model = optimize_for_mobile(traced_script_module)\n",
        "optimized_traced_model._save_for_lite_interpreter(\"model3.py\")"
      ],
      "metadata": {
        "id": "VxsgBAS0IgCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}